{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SlM2E84wu8M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import random\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split as TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1udfNx_Jsxcz",
        "outputId": "1a295eb7-11d8-44aa-d2ea-fcd7801a4d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not found\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "  print(f'GPU found at {device_name}')\n",
        "else:\n",
        "  print('GPU not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTbxMDr97dmR"
      },
      "outputs": [],
      "source": [
        "PATH = './drive/MyDrive/SisFall_Preprocessed/'\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "plt.rcParams['figure.figsize'] = (20,10)\n",
        "\n",
        "SEED = 2021\n",
        "def seedEverything(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "seedEverything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV4qxCSY70y4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_pickle(os.path.join(PATH,'sensor_data.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpGyhfRg8Ej-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "e41ef5c7-8a8c-440b-d623-e65a553910c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e793a235-ab0a-4570-8d10-b8628538d7f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C0</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>filename</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[6.0, 4.0, 5.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, ...</td>\n",
              "      <td>[-223.0, -224.0, -226.0, -222.0, -223.0, -224....</td>\n",
              "      <td>[149.0, 146.0, 145.0, 144.0, 144.0, 149.0, 146...</td>\n",
              "      <td>[-12.0, -12.0, -14.0, -14.0, -17.0, -18.0, -19...</td>\n",
              "      <td>[60.0, 59.0, 60.0, 61.0, 63.0, 65.0, 69.0, 70....</td>\n",
              "      <td>[-5.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2....</td>\n",
              "      <td>[46.0, 47.0, 50.0, 47.0, 49.0, 48.0, 46.0, 48....</td>\n",
              "      <td>[-878.0, -882.0, -878.0, -883.0, -883.0, -880....</td>\n",
              "      <td>[568.0, 568.0, 566.0, 569.0, 568.0, 568.0, 571...</td>\n",
              "      <td>D17_SE11_R05.txt</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-1.0, 1.0, 1.0, -1.0, 1.0, -3.0, 1.0, -2.0, 0...</td>\n",
              "      <td>[-251.0, -252.0, -254.0, -252.0, -253.0, -254....</td>\n",
              "      <td>[-66.0, -66.0, -64.0, -64.0, -64.0, -64.0, -62...</td>\n",
              "      <td>[-18.0, -20.0, -20.0, -18.0, -15.0, -12.0, -10...</td>\n",
              "      <td>[74.0, 75.0, 75.0, 76.0, 77.0, 77.0, 78.0, 78....</td>\n",
              "      <td>[-2.0, -3.0, -3.0, -3.0, -4.0, -4.0, -4.0, -4....</td>\n",
              "      <td>[33.0, 28.0, 28.0, 27.0, 31.0, 30.0, 30.0, 32....</td>\n",
              "      <td>[-974.0, -978.0, -976.0, -984.0, -984.0, -979....</td>\n",
              "      <td>[-284.0, -284.0, -285.0, -289.0, -286.0, -283....</td>\n",
              "      <td>D16_SE11_R05.txt</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 7.0, 7.0, ...</td>\n",
              "      <td>[-222.0, -225.0, -224.0, -224.0, -224.0, -225....</td>\n",
              "      <td>[144.0, 144.0, 145.0, 146.0, 146.0, 143.0, 146...</td>\n",
              "      <td>[-14.0, -13.0, -13.0, -13.0, -12.0, -12.0, -14...</td>\n",
              "      <td>[66.0, 65.0, 63.0, 66.0, 66.0, 69.0, 69.0, 70....</td>\n",
              "      <td>[-4.0, -6.0, -6.0, -7.0, -7.0, -7.0, -8.0, -11...</td>\n",
              "      <td>[57.0, 60.0, 59.0, 59.0, 57.0, 54.0, 59.0, 58....</td>\n",
              "      <td>[-883.0, -884.0, -886.0, -881.0, -884.0, -879....</td>\n",
              "      <td>[566.0, 569.0, 568.0, 564.0, 564.0, 565.0, 567...</td>\n",
              "      <td>D17_SE11_R04.txt</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1.0, 0.0, 0.0, 4.0, 4.0, -2.0, 3.0, 4.0, 1.0,...</td>\n",
              "      <td>[-248.0, -247.0, -246.0, -246.0, -251.0, -252....</td>\n",
              "      <td>[-75.0, -77.0, -76.0, -75.0, -74.0, -78.0, -77...</td>\n",
              "      <td>[1.0, -2.0, -4.0, -6.0, -8.0, -7.0, -6.0, -3.0...</td>\n",
              "      <td>[78.0, 79.0, 78.0, 76.0, 76.0, 75.0, 74.0, 72....</td>\n",
              "      <td>[-2.0, 0.0, -2.0, -1.0, -1.0, -2.0, -1.0, -1.0...</td>\n",
              "      <td>[28.0, 33.0, 27.0, 32.0, 35.0, 35.0, 29.0, 33....</td>\n",
              "      <td>[-957.0, -955.0, -956.0, -961.0, -959.0, -960....</td>\n",
              "      <td>[-341.0, -343.0, -341.0, -338.0, -339.0, -336....</td>\n",
              "      <td>D16_SE11_R04.txt</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-19.0, -17.0, -16.0, -19.0, -18.0, -19.0, -18...</td>\n",
              "      <td>[-237.0, -240.0, -236.0, -239.0, -240.0, -237....</td>\n",
              "      <td>[119.0, 121.0, 132.0, 115.0, 118.0, 118.0, 118...</td>\n",
              "      <td>[-13.0, -9.0, -5.0, -4.0, -3.0, -4.0, -4.0, -1...</td>\n",
              "      <td>[72.0, 74.0, 76.0, 78.0, 78.0, 79.0, 78.0, 73....</td>\n",
              "      <td>[-5.0, -8.0, -8.0, -10.0, -10.0, -10.0, -11.0,...</td>\n",
              "      <td>[-40.0, -48.0, -46.0, -45.0, -44.0, -41.0, -32...</td>\n",
              "      <td>[-941.0, -941.0, -935.0, -937.0, -937.0, -935....</td>\n",
              "      <td>[455.0, 458.0, 452.0, 454.0, 460.0, 462.0, 453...</td>\n",
              "      <td>D17_SE11_R02.txt</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e793a235-ab0a-4570-8d10-b8628538d7f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e793a235-ab0a-4570-8d10-b8628538d7f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e793a235-ab0a-4570-8d10-b8628538d7f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  C0  \\\n",
              "0  [6.0, 4.0, 5.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, ...   \n",
              "1  [-1.0, 1.0, 1.0, -1.0, 1.0, -3.0, 1.0, -2.0, 0...   \n",
              "2  [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 7.0, 7.0, ...   \n",
              "3  [1.0, 0.0, 0.0, 4.0, 4.0, -2.0, 3.0, 4.0, 1.0,...   \n",
              "4  [-19.0, -17.0, -16.0, -19.0, -18.0, -19.0, -18...   \n",
              "\n",
              "                                                  C1  \\\n",
              "0  [-223.0, -224.0, -226.0, -222.0, -223.0, -224....   \n",
              "1  [-251.0, -252.0, -254.0, -252.0, -253.0, -254....   \n",
              "2  [-222.0, -225.0, -224.0, -224.0, -224.0, -225....   \n",
              "3  [-248.0, -247.0, -246.0, -246.0, -251.0, -252....   \n",
              "4  [-237.0, -240.0, -236.0, -239.0, -240.0, -237....   \n",
              "\n",
              "                                                  C2  \\\n",
              "0  [149.0, 146.0, 145.0, 144.0, 144.0, 149.0, 146...   \n",
              "1  [-66.0, -66.0, -64.0, -64.0, -64.0, -64.0, -62...   \n",
              "2  [144.0, 144.0, 145.0, 146.0, 146.0, 143.0, 146...   \n",
              "3  [-75.0, -77.0, -76.0, -75.0, -74.0, -78.0, -77...   \n",
              "4  [119.0, 121.0, 132.0, 115.0, 118.0, 118.0, 118...   \n",
              "\n",
              "                                                  C3  \\\n",
              "0  [-12.0, -12.0, -14.0, -14.0, -17.0, -18.0, -19...   \n",
              "1  [-18.0, -20.0, -20.0, -18.0, -15.0, -12.0, -10...   \n",
              "2  [-14.0, -13.0, -13.0, -13.0, -12.0, -12.0, -14...   \n",
              "3  [1.0, -2.0, -4.0, -6.0, -8.0, -7.0, -6.0, -3.0...   \n",
              "4  [-13.0, -9.0, -5.0, -4.0, -3.0, -4.0, -4.0, -1...   \n",
              "\n",
              "                                                  C4  \\\n",
              "0  [60.0, 59.0, 60.0, 61.0, 63.0, 65.0, 69.0, 70....   \n",
              "1  [74.0, 75.0, 75.0, 76.0, 77.0, 77.0, 78.0, 78....   \n",
              "2  [66.0, 65.0, 63.0, 66.0, 66.0, 69.0, 69.0, 70....   \n",
              "3  [78.0, 79.0, 78.0, 76.0, 76.0, 75.0, 74.0, 72....   \n",
              "4  [72.0, 74.0, 76.0, 78.0, 78.0, 79.0, 78.0, 73....   \n",
              "\n",
              "                                                  C5  \\\n",
              "0  [-5.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2....   \n",
              "1  [-2.0, -3.0, -3.0, -3.0, -4.0, -4.0, -4.0, -4....   \n",
              "2  [-4.0, -6.0, -6.0, -7.0, -7.0, -7.0, -8.0, -11...   \n",
              "3  [-2.0, 0.0, -2.0, -1.0, -1.0, -2.0, -1.0, -1.0...   \n",
              "4  [-5.0, -8.0, -8.0, -10.0, -10.0, -10.0, -11.0,...   \n",
              "\n",
              "                                                  C6  \\\n",
              "0  [46.0, 47.0, 50.0, 47.0, 49.0, 48.0, 46.0, 48....   \n",
              "1  [33.0, 28.0, 28.0, 27.0, 31.0, 30.0, 30.0, 32....   \n",
              "2  [57.0, 60.0, 59.0, 59.0, 57.0, 54.0, 59.0, 58....   \n",
              "3  [28.0, 33.0, 27.0, 32.0, 35.0, 35.0, 29.0, 33....   \n",
              "4  [-40.0, -48.0, -46.0, -45.0, -44.0, -41.0, -32...   \n",
              "\n",
              "                                                  C7  \\\n",
              "0  [-878.0, -882.0, -878.0, -883.0, -883.0, -880....   \n",
              "1  [-974.0, -978.0, -976.0, -984.0, -984.0, -979....   \n",
              "2  [-883.0, -884.0, -886.0, -881.0, -884.0, -879....   \n",
              "3  [-957.0, -955.0, -956.0, -961.0, -959.0, -960....   \n",
              "4  [-941.0, -941.0, -935.0, -937.0, -937.0, -935....   \n",
              "\n",
              "                                                  C8          filename  target  \n",
              "0  [568.0, 568.0, 566.0, 569.0, 568.0, 568.0, 571...  D17_SE11_R05.txt       0  \n",
              "1  [-284.0, -284.0, -285.0, -289.0, -286.0, -283....  D16_SE11_R05.txt       0  \n",
              "2  [566.0, 569.0, 568.0, 564.0, 564.0, 565.0, 567...  D17_SE11_R04.txt       0  \n",
              "3  [-341.0, -343.0, -341.0, -338.0, -339.0, -336....  D16_SE11_R04.txt       0  \n",
              "4  [455.0, 458.0, 452.0, 454.0, 460.0, 462.0, 453...  D17_SE11_R02.txt       0  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [f'C{i}' for i in range(9)]\n",
        "np.array(df[cols].values.tolist()).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH9t9CJWBv8e",
        "outputId": "695ee6e7-d98b-45ec-e6d2-98ed6c9a1ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4221, 9, 1999)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCfgwgu5klc5"
      },
      "outputs": [],
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def scaled_dot_product_attention(self, q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "    if mask is not None:\n",
        "      scaled_attention_logits += (mask * -1e9)  \n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    q = self.wq(q)\n",
        "    k = self.wk(k)\n",
        "    v = self.wv(v)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)\n",
        "    k = self.split_heads(k, batch_size)\n",
        "    v = self.split_heads(v, batch_size)\n",
        "\n",
        "    scaled_attention, attention_weights = self.scaled_dot_product_attention(q, k, v, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "    output = self.dense(concat_attention)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = self.point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def point_wise_feed_forward_network(self, d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model)\n",
        "    ])\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask) \n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output) \n",
        "\n",
        "    ffn_output = self.ffn(out1)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output) \n",
        "\n",
        "    return out2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7BZbMUV3VIT"
      },
      "outputs": [],
      "source": [
        "def build_sub_model(inp, name):\n",
        "  pos_enc = positional_encoding(SEQ_LEN, D_MODEL)\n",
        "  x_axis = tf.keras.layers.Dense(D_MODEL,\n",
        "                                 name=f'{name}_x_axis', \n",
        "                                 use_bias=False)(inp[..., 0])\n",
        "  y_axis = tf.keras.layers.Dense(D_MODEL, \n",
        "                                 name=f'{name}_y_axis',\n",
        "                                 use_bias=False)(inp[..., 1])\n",
        "  z_axis = tf.keras.layers.Dense(D_MODEL, \n",
        "                                 name=f'{name}_z_axis', \n",
        "                                 use_bias=False)(inp[..., 2])\n",
        "\n",
        "  axis_add = tf.keras.layers.Add(name=f'{name}_axis_add')([x_axis, y_axis, z_axis])\n",
        "  x = tf.keras.layers.Add(name=f'{name}_pos_enc_add')([pos_enc, axis_add])\n",
        "\n",
        "  for _ in range(N_ENCODER_LAYER):\n",
        "    x = EncoderLayer(d_model = D_MODEL,\n",
        "                     num_heads = NUM_HEADS,\n",
        "                     dff = D_MODEL * 4,\n",
        "                     rate = LR)(x, mask=None)\n",
        "  x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "  out = tf.keras.layers.Dropout(0.25, name=f'{name}_output')(x)\n",
        "\n",
        "  return out\n",
        "\n",
        "def build_model():\n",
        "  acc_1_inp = tf.keras.Input(shape=(SEQ_LEN, 3), name='accelaration_1_sensor_input')\n",
        "  acc_2_inp = tf.keras.Input(shape=(SEQ_LEN, 3), name='accelaration_2_sensor_input')\n",
        "  rot_inp = tf.keras.Input(shape=(SEQ_LEN, 3), name='rotational_sensor_input')\n",
        "\n",
        "  acc_1_out = build_sub_model(acc_1_inp, name='accelaration_1')\n",
        "  acc_2_out = build_sub_model(acc_2_inp, name='accelaration_2')\n",
        "  rot_out = build_sub_model(rot_inp, name='rotational')\n",
        "\n",
        "  x = tf.keras.layers.Add()([acc_1_out, acc_2_out, rot_out])\n",
        "  out = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(x)\n",
        "  model = tf.keras.Model([acc_1_inp, acc_2_inp, rot_inp], out)\n",
        "  return model\n",
        "\n",
        "#tf.keras.utils.plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqB4IwEwleXD"
      },
      "outputs": [],
      "source": [
        "SEQ_LEN = 256\n",
        "TYPE_1_ACC = ['C0','C1','C2']\n",
        "TYPE_2_ACC = ['C6','C7','C8']\n",
        "ROT_COLS = ['C3','C4','C5']\n",
        "USE_COLS = TYPE_1_ACC + TYPE_2_ACC + ROT_COLS # if USE_ACC == 1 else TYPE_2_ACC + ROT_COLS\n",
        "\n",
        "def get_tensor_data(data,idx=None):\n",
        "  if idx is None:\n",
        "    data = tf.constant(data[USE_COLS].values.tolist())\n",
        "  else:\n",
        "    data = tf.constant(data[USE_COLS].iloc[idx].values.tolist())\n",
        "  data = tf.cast(data, tf.int32)\n",
        "  data = tf.reshape(data, (-1, 1999, len(USE_COLS)))\n",
        "  data = data[:,-SEQ_LEN:,]\n",
        "  \n",
        "  acc_1 = data[:,:,:3]\n",
        "  acc_2 = data[:,:,3:6]\n",
        "  rot = data[:,:,6:]\n",
        "\n",
        "  return acc_1, acc_2, rot\n",
        "\n",
        "\n",
        "train, test, train_label, test_label = TTS(df[USE_COLS], \n",
        "                                           df['target'], \n",
        "                                           stratify=df['target'],\n",
        "                                           test_size=0.1, \n",
        "                                           random_state=SEED)\n",
        "test = get_tensor_data(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p4nLjlTFgZMd"
      },
      "outputs": [],
      "source": [
        "D_MODEL = 24\n",
        "N_ENCODER_LAYER = 6\n",
        "NUM_HEADS = 4\n",
        "LR = 0.01\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 1\n",
        "N_SPLITS = 5\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS)\n",
        "val_score = 0\n",
        "test_preds = 0\n",
        "\n",
        "#config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
        "#sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n",
        "#tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "\n",
        "for i, (tr_idx, val_idx) in enumerate(skf.split(train[USE_COLS], train_label)):\n",
        "  print(f'Running on fold : {i+1}')\n",
        "  \n",
        "  x_train = get_tensor_data(train[USE_COLS], tr_idx)\n",
        "  y_train = train_label.iloc[tr_idx]\n",
        "\n",
        "  x_val = get_tensor_data(train[USE_COLS], val_idx)\n",
        "  y_val = train_label.iloc[val_idx]\n",
        "\n",
        "  with strategy.scope():\n",
        "    tf.keras.backend.clear_session()\n",
        "    model = build_model()\n",
        "    model.compile(\n",
        "        optimizer='adam', \n",
        "        loss='binary_crossentropy', \n",
        "        metrics=[tf.keras.metrics.AUC(name='AUC')]\n",
        "    )\n",
        "\n",
        "  checkpoint_filepath = './checkpoint'\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                  save_weights_only=True,\n",
        "                                                  monitor='val_AUC',\n",
        "                                                  mode='max',\n",
        "                                                  save_best_only=True,\n",
        "                                                  verbose=True)\n",
        "\n",
        "  lrSchedule = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_AUC', \n",
        "                                                    mode='max',\n",
        "                                                    factor=0.025,\n",
        "                                                    patience=10,\n",
        "                                                    verbose=True)\n",
        "  \n",
        "  model.fit(x_train, y_train,\n",
        "            validation_data=(x_val, y_val),\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            callbacks=[checkpoint, lrSchedule],\n",
        "            verbose=True)\n",
        "  \n",
        "  model.load_weights(checkpoint_filepath)\n",
        "\n",
        "  eval_result = model.evaluate(x_val, y_val)\n",
        "  val_score += eval_result[-1]\n",
        "  test_preds += model.predict(test)\n",
        "\n",
        "  print('='*75)\n",
        "\n",
        "print(f'OOF_validation_score : {val_score/N_SPLITS}')\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kfCmVAB-gZEi"
      },
      "outputs": [],
      "source": [
        "print(f'OOF_validation_score : {val_score/N_SPLITS}')\n",
        "test_score = roc_auc_score(test_label, test_preds/N_SPLITS)\n",
        "print(f'Test Score : {test_score}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FYP Transformer Model",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}